# ğŸ§¬ Breast Cancer Classification â€” End-to-End Machine Learning Pipeline

A full end-to-end machine learning project using the **Breast Cancer Wisconsin (Diagnostic) Dataset**, implementing:

- Automated preprocessing  
- Feature engineering  
- Feature selection (multi-method consensus)  
- Model benchmarking  
- Hyperparameter tuning  
- Explainability with SHAP  
- Error analysis  
- Production-ready inference pipeline (`predict.py`)  

This project follows an industry-grade structure suitable for real deployment and serves as a strong portfolio example for **Data Science / ML Engineering** roles.

---

## ğŸ”‘ Keywords  
Machine Learning, Classification, Breast Cancer, SHAP, Explainability, Medical AI, Gradient Boosting, Model Evaluation, Predictive Modeling, Python, scikit-learn, Healthcare Analytics, Pipeline, Feature Engineering

---

## ğŸ“Œ 1. Project Objective

Develop a robust and clinically interpretable machine learning model capable of classifying tumors as **benign** or **malignant** based on radiological measurements of cell nuclei.

Special focus areas:

- Clinical interpretability  
- Minimizing false negatives  
- SHAP-based explainability  
- Reliable production-ready inference  
- Clean, modular ML engineering practices  

---

## ğŸ“Š 2. Dataset Overview

**Source:**  
https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data

- **Rows:** 569  
- **Features:** 30 numerical predictors  
- **Target:**  
  - `M` â†’ Malignant  
  - `B` â†’ Benign  

The dataset contains **no missing values**. Outliers were analyzed but **not removed**, as malignant cases naturally exhibit extreme tumor morphology.

---

## ğŸ§± 3. Project Architecture

```
project_root/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â””â”€â”€ processed/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_EDA.ipynb
â”‚ â”œâ”€â”€ 02_Preprocessing.ipynb
â”‚ â”œâ”€â”€ 03_Modeling.ipynb
â”‚ â”œâ”€â”€ 04_Feature_Selection.ipynb
â”‚ â”œâ”€â”€ 05_Hyperparameter_Tuning.ipynb
â”‚ â”œâ”€â”€ 06_Model_Evaluation.ipynb
â”‚ â””â”€â”€ 07_Testing_Inference.ipynb
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ config.py
â”‚ â”œâ”€â”€ data/preprocessing.py
â”‚ â”œâ”€â”€ models/final_model.pkl
â”‚ â””â”€â”€ inference/predict.py
â”‚
â”œâ”€â”€ imgs/ # Figures displayed in this README
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ 4. Technologies Used

- Python 3.10+  
- scikit-learn  
- pandas, numpy  
- seaborn, matplotlib, plotly  
- SHAP  
- joblib  
- JupyterLab  

---

## ğŸ§¼ 5. Preprocessing Overview

The preprocessing pipeline includes:

- Label encoding (`M`/`B` â†’ 1/0)  
- Standard scaling (fitted only on training data)  
- Feature engineering (`*_avg` smoothed features)  
- Variance filtering  
- Train/test splitting  
- Persisting datasets and scalers  

Outliers were preserved due to their clinical relevance in malignant tumors.

---

## ğŸ§  6. Feature Selection (Consensus Approach)

A multi-method feature selection strategy was used to reduce noise and increase classifier robustness by combining:

- ANOVA F-test  
- Mutual Information  
- SelectKBest  
- Random Forest importance  
- Gradient Boosting importance  
- SHAP global impact  
- Clinical interpretability  

A feature was selected only if it consistently appeared as relevant across **multiple methods** and matched tumor morphology patterns.

### ğŸ“Š Feature Selection Consensus Table

| Feature                 | ANOVA | RF Importance | GB Importance | SHAP | Final Choice |
|-------------------------|:-----:|:-------------:|:-------------:|:----:|:------------:|
| concave_points_mean     | â­â­â­  | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | âœ” |
| concavity_worst         | â­â­â­  | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | âœ” |
| symmetry_worst          | â­â­   | â­â­   | â­â­â­  | â­â­   | âœ” |
| radius_avg              | â­â­â­  | â­â­â­  | â­â­â­  | â­â­â­  | âœ” |
| perimeter_avg           | â­â­â­  | â­â­â­  | â­â­â­  | â­â­â­  | âœ” |
| area_avg                | â­â­â­  | â­â­â­â­ | â­â­â­â­ | â­â­â­  | âœ” |
| radius_mean             | â­â­â­  | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | âœ” |
| texture_mean            | â­â­   | â­â­   | â­â­   | â­â­   | âœ” |
| perimeter_mean          | â­â­â­  | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | âœ” |
| area_mean               | â­â­â­  | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | âœ” |
| smoothness_mean         | â­â­   | â­â­   | â­â­   | â­â­   | âœ” |
| compactness_mean        | â­â­   | â­â­   | â­â­   | â­    | âœ” |
| concavity_mean          | â­â­â­  | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | âœ” |
| symmetry_mean           | â­â­   | â­â­   | â­â­   | â­â­   | âœ” |
| fractal_dimension_mean  | â­    | â­â­   | â­â­   | â­    | âœ” |

---

## ğŸ“‰ 7. EDA â€” Correlation & Feature Insights

### ğŸ” Interactive Correlation Heatmap (Plotly)

ğŸ‘‰ [Click here to view the interactive heatmap](imgs/heatmap_75%.html)

This visualization helped identify multicollinearity and informed the consensus-based feature selection strategy.

---

## ğŸ¤– 8. Model Benchmarking

The following classifiers were trained and evaluated:

- Logistic Regression  
- SVM (RBF Kernel)  
- Random Forest  
- KNN  
- **Gradient Boosting (final model)**  

### ğŸ“Š Benchmark Results

| Model               | Accuracy | Precision | Recall | F1   | ROC_AUC |
|--------------------|---------:|----------:|-------:|------:|--------:|
| Logistic Regression | 0.947 | 0.909 | 0.952 | 0.930 | 0.992 |
| Random Forest       | 0.938 | 0.973 | 0.857 | 0.911 | 0.992 |
| **Gradient Boosting** | **0.973** | **1.000** | **0.928** | **0.962** | **0.992** |
| SVC (RBF)           | 0.956 | 0.974 | 0.904 | 0.938 | 0.985 |
| KNN                 | 0.964 | 0.975 | 0.928 | 0.951 | 0.972 |

> âœ” **Gradient Boosting** was selected for its superior recall stability and SHAP interpretability.

---

## ğŸ“ˆ 9. Model Evaluation

### ğŸ”¢ Confusion Matrix  
The model achieved **zero false positives** and extremely low false negatives â€” critical for clinical settings.

![Confusion Matrix](imgs/confusion_matrix.png)

---

### ğŸ“ˆ ROC Curve  
An exceptional **AUC = 0.992** demonstrates high class separability.

![ROC Curve](imgs/roc_curve.png)

---

## ğŸ§  10. Explainability (SHAP)

SHAP was used to validate feature importance and ensure clinical interpretability.

### ğŸ§¬ SHAP Summary Plot  

![SHAP Summary Plot](imgs/shap_summary.png)

Key insights:

- `concave_points_mean` and `concavity_worst` dominate malignancy prediction  
- Size-related features (`radius`, `area`, `perimeter`) significantly increase malignant probability  
- Symmetry-based features are useful for classifying borderline tumors  

---

## ğŸ” 11. Error Analysis

- **False negatives** mostly occur on borderline malignant cases  
- **False positives** appear in high-variance benign samples  
- Error distribution aligns with clinical expectations

---

## ğŸ§ª 12. Inference Pipeline (Production-Ready)

Located in: `src/inference/predict.py`.

### Single Sample Prediction

```python
from src.inference.predict import PredictionPipeline

pipeline = PredictionPipeline()
pipeline.predict_single({
    "radius_mean": 14.1,
    "texture_mean": 20.3,
    ...
})
```

### Batch Prediction

```python

df = pd.read_csv("new_samples.csv")
pipeline.predict_batch(df)

```

---

## ğŸ“¦ 13. Running the Full Pipeline

All development steps are available in the notebooks/ folder:

1. EDA
2. Preprocessing
3. Modeling
4. Feature Selection
5. Hyperparameter Tuning
6. Model Evaluation
7. Inference Testing

---

## ğŸ› ï¸ 14. Future Work

FastAPI deployment
Dockerization
Nested cross-validation
SMOTE experiments
MLflow tracking
Drift monitoring

---

## ğŸ‘¤ Author

Mateus Vieira Vasconcelos
Data Science & Machine Learning Enthusiast